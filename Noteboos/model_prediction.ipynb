{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c652021",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, gc, random, inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2f404",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================\n",
    "# Submission-only pipeline for Kaggle:\n",
    "# - Clean labels\n",
    "# - Robust Feature Engineering (fit on train, apply to test)\n",
    "# - Version-agnostic sparse OneHot\n",
    "# - XGBoost (DMatrix API) with early stopping on a small validation slice\n",
    "# - Predict ONLY test.csv and save 'submission.csv' as id,exam_score\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Reproducibility\n",
    "# ---------------------------\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def stratify_bins(y, n_bins=10):\n",
    "    y = pd.Series(y).astype(float).clip(lower=0)\n",
    "    try:\n",
    "        bins = pd.qcut(y, q=n_bins, labels=False, duplicates='drop')\n",
    "    except Exception:\n",
    "        bins = pd.cut(y, bins=n_bins, labels=False)\n",
    "    return bins.fillna(0).astype(int)\n",
    "\n",
    "def gpu_available():\n",
    "    return os.path.exists(\"/proc/driver/nvidia/version\")\n",
    "\n",
    "def save_submission_strict(df_test, id_col, preds, path=\"submission.csv\", clip_min=0.0, clip_max=None):\n",
    "    preds = np.asarray(preds, dtype=np.float64)\n",
    "    # ensure length & order exactly match df_test\n",
    "    assert len(preds) == len(df_test), f\"Preds ({len(preds)}) != test rows ({len(df_test)})\"\n",
    "\n",
    "    # replace accidental NaNs with mean\n",
    "    if np.isnan(preds).any():\n",
    "        preds = np.where(np.isnan(preds), np.nanmean(preds), preds)\n",
    "\n",
    "    if clip_min is not None:\n",
    "        preds = np.maximum(preds, clip_min)\n",
    "    if clip_max is not None:\n",
    "        preds = np.minimum(preds, clip_max)\n",
    "\n",
    "    sub = pd.DataFrame({\"id\": df_test[id_col].values, \"exam_score\": preds})\n",
    "    # hard checks\n",
    "    assert sub.shape[0] == df_test.shape[0], \"Row count mismatch!\"\n",
    "    assert np.array_equal(sub[\"id\"].values, df_test[id_col].values), \"ID order mismatch!\"\n",
    "\n",
    "    sub.to_csv(path, index=False)\n",
    "    print(f\"âœ… Saved {path} with {len(sub)} rows.\")\n",
    "    print(sub.head())\n",
    "\n",
    "# ---------------------------\n",
    "# Robust Feature Engineering (fit/transform)\n",
    "# ---------------------------\n",
    "class RobustAcademicFE:\n",
    "    def __init__(self, clip_quantiles=(0.01, 0.99)):\n",
    "        self.clip_quantiles = clip_quantiles\n",
    "        self._num_clip_bounds = {}\n",
    "        self._drop_all_nan_cols = []\n",
    "        self.sleep_map = {\"very poor\":1,\"poor\":2,\"fair\":3,\"average\":3,\"okay\":3,\"good\":4,\"very good\":5,\"excellent\":6}\n",
    "        self.exam_diff_map = {\"very easy\":1,\"easy\":2,\"medium\":3,\"hard\":4,\"very hard\":5}\n",
    "        self.facility_map  = {\"very bad\":1,\"bad\":2,\"average\":3,\"good\":4,\"very good\":5,\"excellent\":6}\n",
    "        self._synonyms = {\"ok\":\"okay\",\"vg\":\"very good\",\"v good\":\"very good\",\"v bad\":\"very bad\"}\n",
    "\n",
    "    def _n(self, x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        return str(x).strip().lower()\n",
    "\n",
    "    def _map_ordinal(self, s, base_map, numeric_ok=True):\n",
    "        def conv(v):\n",
    "            vn = self._n(v)\n",
    "            if vn is np.nan: return np.nan\n",
    "            if vn in self._synonyms: vn = self._synonyms[vn]\n",
    "            if numeric_ok:\n",
    "                try: return float(vn)\n",
    "                except Exception: pass\n",
    "            return base_map.get(vn, np.nan)\n",
    "        return s.map(conv)\n",
    "\n",
    "    def _engineer(self, df):\n",
    "        df = df.copy()\n",
    "        # Ordinals\n",
    "        if \"sleep_quality\" in df:\n",
    "            df[\"sleep_quality_ord\"] = self._map_ordinal(df[\"sleep_quality\"], self.sleep_map)\n",
    "        if \"exam_difficulty\" in df:\n",
    "            df[\"exam_difficulty_ord\"] = self._map_ordinal(df[\"exam_difficulty\"], self.exam_diff_map)\n",
    "        if \"facility_rating\" in df:\n",
    "            df[\"facility_rating_ord\"] = self._map_ordinal(df[\"facility_rating\"], self.facility_map)\n",
    "        # Interactions\n",
    "        if \"study_hours\" in df and \"class_attendance\" in df:\n",
    "            df[\"study_x_attendance\"] = df[\"study_hours\"] * df[\"class_attendance\"]\n",
    "        if \"sleep_hours\" in df and \"sleep_quality_ord\" in df:\n",
    "            df[\"sleep_effective\"] = df[\"sleep_hours\"] * df[\"sleep_quality_ord\"]\n",
    "        # Internet flag\n",
    "        if \"internet_access\" in df:\n",
    "            df[\"has_internet\"] = df[\"internet_access\"].map(\n",
    "                lambda v: 0 if self._n(v) in [\"no\",\"none\",\"null\",\"nan\",\"\"] else 1\n",
    "            )\n",
    "        # Missingness flags\n",
    "        for col in [\"study_hours\",\"class_attendance\",\"sleep_hours\"]:\n",
    "            if col in df:\n",
    "                df[f\"isna_{col}\"] = df[col].isna().astype(int)\n",
    "        return df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        Xb = self._engineer(X)\n",
    "        num_cols = Xb.select_dtypes(include=[\"number\"]).columns\n",
    "        self._drop_all_nan_cols = [c for c in num_cols if Xb[c].notna().sum() == 0]\n",
    "        # learn clipping on key numerics\n",
    "        ql, qh = self.clip_quantiles\n",
    "        for col in [\"study_hours\",\"class_attendance\",\"sleep_hours\"]:\n",
    "            if col in Xb:\n",
    "                low, high = Xb[col].quantile([ql, qh])\n",
    "                self._num_clip_bounds[col] = (float(low), float(high))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xb = self._engineer(X)\n",
    "        Xb = Xb.drop(columns=self._drop_all_nan_cols, errors=\"ignore\")\n",
    "        for col, (low, high) in self._num_clip_bounds.items():\n",
    "            if col in Xb:\n",
    "                Xb[col] = Xb[col].clip(lower=low, upper=high)\n",
    "        return Xb\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "# ---------------------------\n",
    "# Load data\n",
    "# ---------------------------\n",
    "train_path = \"train.csv\"\n",
    "test_path  = \"test.csv\"\n",
    "assert os.path.exists(train_path) and os.path.exists(test_path), \"Put train.csv and test.csv in the working directory.\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "TARGET = \"exam_score\"\n",
    "ID_COL = \"id\"\n",
    "EXCLUDE = {TARGET, ID_COL, \"Transported\"}  # exclude id, target, unrelated columns\n",
    "\n",
    "assert TARGET in df_train.columns, f\"{TARGET} missing in train.csv\"\n",
    "assert ID_COL in df_test.columns,  f\"{ID_COL} missing in test.csv\"\n",
    "\n",
    "\n",
    "df_train[TARGET] = pd.to_numeric(df_train[TARGET], errors=\"coerce\")\n",
    "mask = df_train[TARGET].notna() & np.isfinite(df_train[TARGET].values) & (df_train[TARGET].abs() < 1e9)\n",
    "dropped = (~mask).sum()\n",
    "if dropped > 0:\n",
    "    print(f\"[Label clean] Dropped {dropped} train rows with NaN/Inf/unreasonable {TARGET}.\")\n",
    "df_train = df_train.loc[mask].reset_index(drop=True)\n",
    "\n",
    "\n",
    "feature_cols = [c for c in df_train.columns if c not in EXCLUDE]\n",
    "X_full_raw = df_train[feature_cols].copy()\n",
    "y_full     = df_train[TARGET].astype(float).values\n",
    "X_test_raw = df_test[feature_cols].copy()\n",
    "\n",
    "\n",
    "fe = RobustAcademicFE()\n",
    "X_full_fe = fe.fit_transform(X_full_raw)\n",
    "X_test_fe = fe.transform(X_test_raw)\n",
    "\n",
    "\n",
    "common_cols = sorted(set(X_full_fe.columns) & set(X_test_fe.columns))\n",
    "X_full_fe = X_full_fe[common_cols].copy()\n",
    "X_test_fe = X_test_fe[common_cols].copy()\n",
    "\n",
    "print(f\"Train shape (after FE): {X_full_fe.shape}, Test shape (after FE): {X_test_fe.shape}\")\n",
    "\n",
    "\n",
    "def make_ohe():\n",
    "    kwargs = {\"handle_unknown\":\"ignore\"}\n",
    "    if \"sparse_output\" in inspect.signature(OneHotEncoder).parameters:\n",
    "        kwargs[\"sparse_output\"] = True   # sklearn >= 1.2\n",
    "    else:\n",
    "        kwargs[\"sparse\"] = True          # sklearn < 1.2\n",
    "    return OneHotEncoder(**kwargs)\n",
    "\n",
    "num_cols = X_full_fe.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = X_full_fe.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", make_ohe())\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "\n",
    "bins = stratify_bins(y_full, n_bins=10)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "tr_idx, va_idx = next(sss.split(X_full_fe, bins))\n",
    "\n",
    "X_tr, X_va = X_full_fe.iloc[tr_idx], X_full_fe.iloc[va_idx]\n",
    "y_tr, y_va = y_full[tr_idx], y_full[va_idx]\n",
    "\n",
    "\n",
    "X_tr_enc = pre.fit_transform(X_tr)\n",
    "X_va_enc = pre.transform(X_va)\n",
    "X_te_enc = pre.transform(X_test_fe)\n",
    "\n",
    "use_gpu = gpu_available()\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"tree_method\": \"gpu_hist\" if use_gpu else \"hist\",\n",
    "    \"predictor\": \"gpu_predictor\" if use_gpu else \"auto\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"subsample\": 0.85,\n",
    "    \"colsample_bytree\": 0.75,\n",
    "    \"lambda\": 1.0,\n",
    "    \"random_state\": 42,\n",
    "    \"verbosity\": 0\n",
    "}\n",
    "NUM_ROUNDS = 3500\n",
    "ES_ROUNDS  = 200\n",
    "\n",
    "dtr = xgb.DMatrix(X_tr_enc, label=y_tr)\n",
    "dva = xgb.DMatrix(X_va_enc, label=y_va)\n",
    "dte = xgb.DMatrix(X_te_enc)\n",
    "\n",
    "evals = [(dtr, \"train\"), (dva, \"valid\")]\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtr,\n",
    "    num_boost_round=NUM_ROUNDS,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=ES_ROUNDS,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "# Predict test ONLY (for submission)\n",
    "try:\n",
    "    test_pred = bst.predict(dte, iteration_range=(0, bst.best_iteration + 1))\n",
    "except Exception:\n",
    "    test_pred = bst.predict(dte, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "\n",
    "CLIP_MIN, CLIP_MAX = 0.0, None  # set CLIP_MAX=100.0 if scores are bounded above\n",
    "save_submission_strict(df_test, ID_COL, test_pred, path=\"submission.csv\", clip_min=CLIP_MIN, clip_max=CLIP_MAX)\n",
    "\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
